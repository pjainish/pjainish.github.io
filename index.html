<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.150.0"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Jainish Patel</title><meta name=keywords content="jainish patel,jainish patel blog,jainish patel portfolio,independent consultant,artificial intelligence,data science,machine learning,deep learning,recommendation systems,recommendation engine,retail analytics,data analytics,big data analytics,ai and data science,consulting firms"><meta name=description content><meta name=author content="Jainish Patel"><link rel=canonical href=https://pjainish.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.c539924d894ce2c25182d9de2e87d1928301193ff6039a4ed439c270f51820ce.css integrity="sha256-xTmSTYlM4sJRgtneLofRkoMBGT/2A5pO1DnCcPUYIM4=" rel="preload stylesheet" as=style><link rel=icon href=https://pjainish.github.io/assets/images/favicon.png><link rel=icon type=image/png sizes=16x16 href=https://pjainish.github.io/assets/images/favicon.png><link rel=icon type=image/png sizes=32x32 href=https://pjainish.github.io/assets/images/favicon.png><link rel=apple-touch-icon href=https://pjainish.github.io/assets/images/favicon.png><link rel=mask-icon href=https://pjainish.github.io/assets/images/favicon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://pjainish.github.io/index.xml><link rel=alternate type=application/json href=https://pjainish.github.io/index.json><link rel=alternate hreflang=en href=https://pjainish.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-79V8YMLKHG"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-79V8YMLKHG")</script><meta property="og:url" content="https://pjainish.github.io/"><meta property="og:site_name" content="Jainish Patel"><meta property="og:title" content="Jainish Patel"><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Jainish Patel"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Jainish Patel","url":"https://pjainish.github.io/","description":"","logo":"https://pjainish.github.io/assets/images/favicon.png","sameAs":["https://github.com/pjainish","https://www.linkedin.com/in/jainish360/","https://x.com/jainish360","https://pjainish.github.io/index.xml"]}</script></head><body class="list dark" id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://pjainish.github.io/ accesskey=h title="Jainish Patel (Alt + H)"><img src=https://pjainish.github.io/assets/images/favicon.png alt aria-label=logo height=30>Jainish Patel</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://pjainish.github.io/ title=Posts><span class=active>Posts</span></a></li><li><a href=https://pjainish.github.io/about title=About><span>About</span></a></li><li><a href=https://pjainish.github.io/categories/case-study/ title="Case Studies"><span>Case Studies</span></a></li><li><a href=https://pjainish.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://pjainish.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://pjainish.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://pjainish.github.io/archives/ title=Archives><span>Archives</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>Hi, I&rsquo;m Jainish Patel !</h1></header><div class=entry-content>I am an AI consultant and Lead Applied Engineer who builds recommendation systems and intelligent applications that solve real-world problems. I believe the best solutions come from understanding both the technology and the human side of every problem. When I&rsquo;m not helping businesses transform with AI, you&rsquo;ll find me exploring connections between cognitive science, physics, and machine learning - or out climbing and running.</div><footer class=entry-footer><div class=social-icons><a href=https://github.com/pjainish target=_blank rel="noopener noreferrer me" title=Github><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</a><a href=https://www.linkedin.com/in/jainish360/ target=_blank rel="noopener noreferrer me" title=Linkedin><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg>
</a><a href=https://x.com/jainish360 target=_blank rel="noopener noreferrer me" title=X><svg viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg>
</a><a href=https://pjainish.github.io/index.xml target=_blank rel="noopener noreferrer me" title=Rss><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></div></footer></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Foundation Models in Recommendation Systems: How AI Language Models Are Revolutionizing Personalized Recommendations</h2></header><div class=entry-content><p>How large language models are transforming recommendation engines from pattern matchers into intelligent reasoning systems that truly understand user preferences
Keywords: foundation models, recommendation systems, large language models, personalized recommendations, AI recommendation engines, machine learning recommendations, LLM recommendation systems
There’s something beautifully ironic happening in recommendation systems right now. For decades, we’ve been obsessed with learning the perfect embedding - that magical vector representation that captures everything about a user or item in a few hundred dimensions. We’ve built elaborate architectures, from collaborative filtering to deep neural networks, all centered around this core idea: learn good embeddings, and recommendations will follow.
...</p></div><footer class=entry-footer><span title='2025-09-18 17:02:56 +0530 IST'>September 18, 2025</span>&nbsp;·&nbsp;47 min&nbsp;·&nbsp;Jainish Patel</footer><a class=entry-link aria-label="post link to Foundation Models in Recommendation Systems: How AI Language Models Are Revolutionizing Personalized Recommendations" href=https://pjainish.github.io/blog/foundation-models-in-recsys/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Incorporating Ads into Large Language Models: The Hidden Economy of AI Responses</h2></header><div class=entry-content><p>The moment you ask ChatGPT about a travel destination and it casually mentions a specific hotel booking platform, or when Claude suggests a particular coding tool while helping with your programming question, you’re witnessing something fascinating: the intersection of artificial intelligence and advertising. What seems like helpful, neutral advice might actually be the result of careful economic engineering beneath the hood of these language models.
This isn’t about banner ads cluttering up your chat interface - that would be crude and obvious. Instead, we’re talking about something far more sophisticated: weaving promotional content seamlessly into the fabric of AI-generated text itself. It’s a practice that’s quietly reshaping how we think about AI neutrality, user trust, and the economics of running these incredibly expensive models.
...</p></div><footer class=entry-footer><span title='2025-06-09 13:00:00 +0530 IST'>June 9, 2025</span>&nbsp;·&nbsp;24 min&nbsp;·&nbsp;Jainish Patel</footer><a class=entry-link aria-label="post link to Incorporating Ads into Large Language Models: The Hidden Economy of AI Responses" href=https://pjainish.github.io/blog/incorporating-ads-into-llms/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Multi-Stage Approach to Building Recommender Systems</h2></header><div class=entry-content><p>Multi-stage recommendation systems break down the challenging task of matching users with relevant items into several sequential phases, each optimizing for different objectives like efficiency, accuracy, and personalization. By progressively narrowing down a vast pool of candidates, applying increasingly complex models, and refining final rankings, these systems achieve scalable and high-quality recommendations even when dealing with billions of users and items (ijcai.org, developers.google.com). They mirror how humans might sift through information: first skimming broadly, then considering details, and finally fine-tuning choices. This blog post explores the conceptual foundations of multi-stage recommendation, the distinct roles of each phase, the motivations behind layered architectures, and the real-world trade-offs they address. Along the way, analogies to everyday decision-making, historical parallels from human learning, and references to psychology illustrate how designers balance speed, relevance, and diversity. Finally, we survey challenges such as latency constraints, fairness, and the evolution toward neural re-ranking and hybrid objectives, pointing curious readers to key research papers and practical guides for deeper study.
...</p></div><footer class=entry-footer><span title='2025-06-03 13:48:45 +0530 IST'>June 3, 2025</span>&nbsp;·&nbsp;35 min&nbsp;·&nbsp;Jainish Patel</footer><a class=entry-link aria-label="post link to Multi-Stage Approach to Building Recommender Systems" href=https://pjainish.github.io/blog/multi-stage-recommender-systems/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Improving Search Relevance Using Large Language Models</h2></header><div class=entry-content><p>Search is the invisible backbone of our digital lives. Every time you type a query into Google, search through Netflix’s catalog, or hunt for a specific product on Amazon, you’re interacting with systems designed to understand what you really want - not just what you literally typed. But here’s the thing: traditional search has always been a bit like playing telephone with a robot that only speaks in keywords.
Large Language Models are changing this game entirely. They’re teaching search systems to understand language the way humans do - with context, nuance, and genuine comprehension. The transformation is so profound that we’re witnessing the biggest shift in information retrieval since the invention of the web crawler. Let me show you how this revolution works and why it’s reshaping everything from how we shop to how we discover knowledge.
...</p></div><footer class=entry-footer><span title='2025-05-03 13:48:45 +0530 IST'>May 3, 2025</span>&nbsp;·&nbsp;29 min&nbsp;·&nbsp;Jainish Patel</footer><a class=entry-link aria-label="post link to Improving Search Relevance Using Large Language Models" href=https://pjainish.github.io/blog/improving-search-relevance-using-large-language-models/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>BERT4Rec : Decoding Sequential Recommendations with the Power of Transformers</h2></header><div class=entry-content><p>BERT4Rec is a sequential recommendation model that leverages the bidirectional Transformer architecture, originally designed for language tasks, to capture users’ evolving preferences by jointly considering both past and future items in a sequence (arxiv.org, github.com). Unlike earlier unidirectional models that predict the next item only from previous ones, BERT4Rec uses a Cloze-style masking objective to predict missing items anywhere in the sequence, enabling richer context modeling (arxiv.org, github.com). Empirical evaluations on multiple benchmark datasets demonstrate that BERT4Rec often surpasses state-of-the-art sequential models like SASRec, though its performance can depend on careful training schedules and hyperparameter choices (arxiv.org, arxiv.org). This post traces the journey from early recommendation methods to the Transformer revolution and the rise of BERT, explains the core ideas behind BERT4Rec, connects them to cognitive analogies of Cloze tests, and discusses experiments, limitations, and future directions. By understanding BERT4Rec’s design and its place in the broader landscape of recommendation, readers can appreciate both its technical elegance and its conceptual roots in language modeling and human learning.
...</p></div><footer class=entry-footer><span title='2025-01-03 17:23:15 +0530 IST'>January 3, 2025</span>&nbsp;·&nbsp;31 min&nbsp;·&nbsp;Jainish Patel</footer><a class=entry-link aria-label="post link to BERT4Rec : Decoding Sequential Recommendations with the Power of Transformers" href=https://pjainish.github.io/blog/bert4rec-sequential-recommendation/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://pjainish.github.io/>Jainish Patel</a></span> ·
<span><a href=https://pjainish.github.io/sitemap.xml>Sitemap</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>